name: Scrape USA Events

on:
  schedule:
    # Mon + Thu at 1:00 AM UTC (8 PM ET / 5 PM PT previous day)
    - cron: '0 1 * * 1,4'
  workflow_dispatch: # Allow manual trigger from GitHub UI

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm install

      - name: Install Playwright Chromium
        run: npx playwright install chromium --with-deps

      - name: Run scrapers
        env:
          WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
        run: npm run scrape

      - name: Export events to static JSON
        env:
          AIRTABLE_API_KEY: ${{ secrets.AIRTABLE_API_KEY }}
          AIRTABLE_BASE_ID: ${{ secrets.AIRTABLE_BASE_ID }}
        run: node scripts/export-events.js

      - name: Commit and push events.json
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add public/events.json
          git diff --staged --quiet || (git commit -m "Update events.json" && git push)

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-logs-${{ github.run_number }}
          path: scrapers/logs/
          retention-days: 90
